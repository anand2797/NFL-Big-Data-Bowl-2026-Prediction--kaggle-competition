
# NFL-Big-Data-Bowl-2026-Prediction--kaggle-competition
Kaggle competition project for the 2026 NFL Big Data Bowl. Predicts future x/y positions of NFL players after a pass using player tracking data. Includes data preprocessing, feature engineering, sequence modeling, predictions, and submission generation.


## 1. Project Structure Automation

This repository includes a `templates.py` script that automatically generates the recommended file and directory structure for the NFL Game Competition project.

### Usage

Run `templates.py` to create all necessary folders and files for the project. This helps maintain consistency and saves setup time for new contributors.

**How it works:**
- The script creates directories and empty files as defined in its `list_of_files` variable.
- It uses Python's `os` and `pathlib` modules for cross-platform compatibility.
- Logging messages indicate which files and folders are created or already exist.

**To run:**
```bash
python templates.py
```
### Example Project Structure
```
nfl_game_competition/
├── artifacts/
│   └── timestamps/     # every time generate dir based on time when we run the pipeline or component
│   └── downloaded_data/
│   └── logs/
├── data_schema/
│   └── schema.yaml  # store info about feature name and datatype and total records
├── notebooks/
│   └── trials.ipynb
├── src/
│   └── nfl_game_competition/
│       ├── components/
│       │   └── __init__.py
│       │   └── data_ingestion.py
│       │   └── data_validation.py
│       │   └── data_transformation.py
│       │   └── model_trainer.py
│       │   └── model_evaluation.py
│       ├── constants/
│       │   └── __init__.py
│       │   └──training_pipeline_constants/
│       │   │  └── __init__.py   # stores all constants
│       ├── entity/
│       │   └── __init__.py
│       │   └── artifact_entity.py
│       │   └── config_entity.py
│       ├── pipeline/
│       │   └── __init__.py
│       │   └── train_pipeline.py
│       │   └── prediction_pipeline.py
│       ├── utils/
│       ├── logger.py
│       └── exception.py
├── templates/
│   └── index.html
├── venv/   # virtual environment which we don't push on git
├── .env   # not push to git
├── .gitignore # we get this file after git clone or pull from git repo
├── app.py
├── main.py
├── params.yaml
├── README.md
├── requirements.txt
├── setup.py
└── templates.py
```


- This structure is auto-generated by `templates.py` and can be customized as needed for your workflow.
- If few files or dir not created by `templates.py` then we can add in it or create manually.



## 2. Connecting to a Git Repository

Below are all possible ways to connect your local project to a git repository:

### a) Before Starting the Project: Clone the Repository
If you want to start with an existing remote repository, use:
```bash
git clone <repo-url>
cd <repo-folder>
```
This will copy all files from the remote repository to your local machine.

### b) After Running templates.py: Pull Latest Files
If you have already generated the project structure locally and want to sync with a remote repository:
```bash
git init
git remote add origin <repo-url>
git fetch origin
git pull origin master  # or main, depending on branch name
```
This will initialize git, connect to the remote, and pull files.

### c) No Files in Repo: Add Files and Push to Remote
If your remote repository is empty and you want to add your local files:
```bash
git init
git remote add origin <repo-url>
git add .
git commit -m "Initial project structure"
git branch -M master  # or main
# If the remote is empty, you may need to force push:
git push -u origin master  # or main
```
This will add all files, commit, and push them to the remote repository.


## 3. Next Steps: Start the Project


After setting up the project structure and connecting to the git repository, you can start developing your NFL Big Data Bowl solution.

### Recommended Steps

**1. Create a Python Virtual Environment and Activate it**

You can use either Conda or venv. Below are commands for both Bash and CMD (Windows) terminals in VS Code:

**a) Using Conda**

- Bash:
	```bash
	conda create -n venv python=3.10 -y
	conda activate venv
    
	```
- CMD (Windows):
	```cmd
	conda create -n venv python=3.10 -y
	conda activate venv/
	```

**b) Using venv (Standard Python Virtual Environment)**

- Bash:
	```bash
	python -m venv venv
	source venv/bin/activate
	```
- CMD (Windows):

	```cmd
	python -m venv venv
	venv\Scripts\activate
	```

**2. Install Project Requirements**

After activating your virtual environment, install the required Python packages:

- Bash or CMD:
	```bash
	pip install -r requirements.txt
	```


**3. Begin development in the appropriate modules (e.g., data ingestion, preprocessing, modeling).**

1. Update constants in `src/nfl_game_competition/constants/training_pipeline_constants/__init__.py `
2. Update config entity in `src/nfl_game_competition/entity/config_entity.py`
3. Update artifact entity in `src/nfl_game_competition/entity/artifact_entity.py`
4. Update the current component in  `src/nfl_game_competition/components/-----.py`
5. Update the pipeline in `src/nfl_game_competition/pipeline/----.py`
6. Update the `main.py`

**4. Use `main.py`  as your entry point for running the whole ml or ds project pipeline.**



